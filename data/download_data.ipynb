{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for downloading/refreshing trainign data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download data from Bloomberg for training\n",
    "Note: \n",
    "- in the future the download script will be rewritten to adapt to a REST api\n",
    "of our choice.\n",
    "- Use the `asia_dd_env` environment for downloading data from bbg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xbbg import blp\n",
    "import numpy as np\n",
    "from typing import Union, Optional, Any, List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# market cap > 500m\n",
    "universe = pd.read_csv(\"./datafiles/mpax_universe_all.csv\", header=[0], index_col=[0], low_memory=False)\n",
    "universe = universe.query(\"`CUR_MKT_CAP_USD`>1e3\")\n",
    "figi_list = universe.ID_BB_GLOBAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_desc = universe.filter([\"SECURITY_NAME\", \"PARSEKYABLE_DES_SOURCE\", \n",
    "                \"GICS_SUB_INDUSTRY\", \"ID_ISIN\", \"UD_ECONOMIC_CORRELATION\", \n",
    "                \"UD_ALGO_RATING\", \"ID_BB_GLOBAL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SECURITY_NAME</th>\n",
       "      <th>PARSEKYABLE_DES_SOURCE</th>\n",
       "      <th>GICS_SUB_INDUSTRY</th>\n",
       "      <th>ID_ISIN</th>\n",
       "      <th>UD_ECONOMIC_CORRELATION</th>\n",
       "      <th>UD_ALGO_RATING</th>\n",
       "      <th>ID_BB_GLOBAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ITOCHU Corp</td>\n",
       "      <td>8001 JP Equity</td>\n",
       "      <td>20107010</td>\n",
       "      <td>JP3143600009</td>\n",
       "      <td>Cyclical</td>\n",
       "      <td>2B</td>\n",
       "      <td>BBG000B9WJ55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Enerpac Tool Group Corp</td>\n",
       "      <td>ATU US Equity</td>\n",
       "      <td>20106020</td>\n",
       "      <td>US2927651040</td>\n",
       "      <td>Cyclical</td>\n",
       "      <td>3</td>\n",
       "      <td>BBG000B9WX45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tatneft PJSC</td>\n",
       "      <td>ATAD LI Equity</td>\n",
       "      <td>10102020</td>\n",
       "      <td>US8766292051</td>\n",
       "      <td>Commodity</td>\n",
       "      <td>7+</td>\n",
       "      <td>BBG000B9X7K3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ameren Corp</td>\n",
       "      <td>AEE US Equity</td>\n",
       "      <td>55103010</td>\n",
       "      <td>US0236081024</td>\n",
       "      <td>Defensive</td>\n",
       "      <td>2A</td>\n",
       "      <td>BBG000B9X8C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Woodside Petroleum Ltd</td>\n",
       "      <td>WPL AU Equity</td>\n",
       "      <td>10102020</td>\n",
       "      <td>AU000000WPL2</td>\n",
       "      <td>Commodity</td>\n",
       "      <td>3+</td>\n",
       "      <td>BBG000B9XBS6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22510</th>\n",
       "      <td>Apogee Therapeutics Inc</td>\n",
       "      <td>APGE US Equity</td>\n",
       "      <td>35201010</td>\n",
       "      <td>US03770N1019</td>\n",
       "      <td>Defensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BBG01H51WYQ5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22511</th>\n",
       "      <td>BGC Group Inc</td>\n",
       "      <td>BGC US Equity</td>\n",
       "      <td>40203020</td>\n",
       "      <td>US0889291045</td>\n",
       "      <td>Cyclical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BBG01H9FTGX5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22512</th>\n",
       "      <td>Atlanta Braves Holdings Inc</td>\n",
       "      <td>BATRA US Equity</td>\n",
       "      <td>50202010</td>\n",
       "      <td>US0477261046</td>\n",
       "      <td>Cyclical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BBG01HCDRG86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22513</th>\n",
       "      <td>Atlanta Braves Holdings Inc</td>\n",
       "      <td>BATRK US Equity</td>\n",
       "      <td>50202010</td>\n",
       "      <td>US0477263026</td>\n",
       "      <td>Cyclical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BBG01HCX3Y34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22514</th>\n",
       "      <td>Howard Hughes Holdings Inc</td>\n",
       "      <td>HHH US Equity</td>\n",
       "      <td>60201030</td>\n",
       "      <td>US44267T1025</td>\n",
       "      <td>Defensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BBG01HTMDZ54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9256 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SECURITY_NAME PARSEKYABLE_DES_SOURCE GICS_SUB_INDUSTRY  \\\n",
       "1                      ITOCHU Corp         8001 JP Equity          20107010   \n",
       "5          Enerpac Tool Group Corp          ATU US Equity          20106020   \n",
       "8                     Tatneft PJSC         ATAD LI Equity          10102020   \n",
       "9                      Ameren Corp          AEE US Equity          55103010   \n",
       "10          Woodside Petroleum Ltd          WPL AU Equity          10102020   \n",
       "...                            ...                    ...               ...   \n",
       "22510      Apogee Therapeutics Inc         APGE US Equity          35201010   \n",
       "22511                BGC Group Inc          BGC US Equity          40203020   \n",
       "22512  Atlanta Braves Holdings Inc        BATRA US Equity          50202010   \n",
       "22513  Atlanta Braves Holdings Inc        BATRK US Equity          50202010   \n",
       "22514   Howard Hughes Holdings Inc          HHH US Equity          60201030   \n",
       "\n",
       "            ID_ISIN UD_ECONOMIC_CORRELATION UD_ALGO_RATING  ID_BB_GLOBAL  \n",
       "1      JP3143600009                Cyclical             2B  BBG000B9WJ55  \n",
       "5      US2927651040                Cyclical              3  BBG000B9WX45  \n",
       "8      US8766292051               Commodity             7+  BBG000B9X7K3  \n",
       "9      US0236081024               Defensive             2A  BBG000B9X8C0  \n",
       "10     AU000000WPL2               Commodity             3+  BBG000B9XBS6  \n",
       "...             ...                     ...            ...           ...  \n",
       "22510  US03770N1019               Defensive            NaN  BBG01H51WYQ5  \n",
       "22511  US0889291045                Cyclical            NaN  BBG01H9FTGX5  \n",
       "22512  US0477261046                Cyclical            NaN  BBG01HCDRG86  \n",
       "22513  US0477263026                Cyclical            NaN  BBG01HCX3Y34  \n",
       "22514  US44267T1025               Defensive            NaN  BBG01HTMDZ54  \n",
       "\n",
       "[9256 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbg_fields = dict(\n",
    "    return_fields = {\"return_com_eqy\", \"normalized_roe\", \"operating_roic\", \"return_on_asset\"},\n",
    "    margin_fields = {\"ebitda_margin\", \"gross_margin\", \"ebit_margin\", \"eff_tax_rate\",\n",
    "            \"fcf_margin_after_oper_lea_pymt\"},\n",
    "    is_fields = {\"sales_rev_turn\", \"net_income\", \"is_rd_expend\", \n",
    "                 \"ardr_selling_general_admin_exp\", \n",
    "            \"is_selling_expenses\", \"is_opex_adjusted\", \"tot_int_exp\"\n",
    "            \"cf_cap_expend_prpty_add\", \"cf_cash_from_oper\"},\n",
    "    leverage_fields = {\"total_debt_to_tot_eqy\", \"net_debt_to_shrhldr_eqty\", \n",
    "            \"net_debt_to_ebitda\", \"fixed_charge_coverage_ratio\"},\n",
    "    bs_ratios = {\"invent_days\", \"acct_rcv_days\", \"days_accounts_payable\", \n",
    "            \"cash_conversion_cycle\", },\n",
    "    est_fields = {\"best_sales\", \"best_gross_margin\", \"best_net_income\"},\n",
    "    best_overrides = [{\"best_fperiod_override\": \"1FY\"}, {\"best_fperiod_override\": \"2FY\"}, {\"best_fperiod_override\": \"3FY\"}]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "default_columns = pd.MultiIndex.from_tuples(\n",
    "    (itertools.chain(*[[(k, i) for i in v] for k, v in bbg_fields.items() \n",
    "                       if k not in (\"est_fields\", \"default_override\", \"best_overrides\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Collection, Sequence, Literal, Dict\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "TODAY = dt.datetime.today().date()\n",
    "\n",
    "def get_hist_financials(\n",
    "        tickers: Collection[str], \n",
    "        start_date: dt.date=dt.date(1995, 1, 1), \n",
    "        end_date: dt.date=TODAY):\n",
    "    hist_fields = set()\n",
    "    for fld_name, fld in bbg_fields.items():\n",
    "        if fld_name not in (\"est_fields\", \"default_override\", \"best_overrides\"):\n",
    "            hist_fields = hist_fields.union(fld)\n",
    "    hist_financials = blp.bdh(tickers, hist_fields, start_date=start_date, \n",
    "                    end_date=end_date, \n",
    "                    Per=\"Y\",\n",
    "                    # **bbg_fields.get(\"default_override\")\n",
    "                    )\n",
    "    hist_financials.index = hist_financials.index.astype(\"datetime64[ns]\").to_series().apply(lambda d: pd.Period(d, freq=\"Y\"))\n",
    "    hist_financials = hist_financials.rename_axis(\"year\", axis=0).rename_axis([\"figi\", \"field\"], axis=1)\n",
    "    hist_financials = hist_financials.reset_index().groupby(\"year\").mean().stack()\\\n",
    "        .unstack(0).reindex(default_columns.get_level_values(1))\n",
    "    hist_financials.index = default_columns[default_columns.get_level_values(1).isin(hist_financials.index)]\n",
    "\n",
    "    # calculated ratios fields\n",
    "    temp_ratios = hist_financials.loc['is_fields'].drop(['sales_rev_turn'], axis=0) / hist_financials.loc['is_fields'].loc['sales_rev_turn']\n",
    "    temp_ratios.index = pd.MultiIndex.from_product(([\"margins\"], temp_ratios.index.to_series().apply(lambda x: f\"{x}_to_sales\").values))\n",
    "    \n",
    "    # calculated growth fields\n",
    "    temp_growth = hist_financials.loc['is_fields'].loc[[\"sales_rev_turn\", \"net_income\"]]\n",
    "    temp_growth = temp_growth.stack(1).unstack(0).pct_change(periods=1).stack(1).unstack(0)\n",
    "    temp_growth.index = pd.MultiIndex.from_product(([\"growth\"], temp_growth.index.to_series().apply(lambda x: f\"{x}_growth\").values))\n",
    "\n",
    "    res = pd.concat([hist_financials.drop(\"is_fields\", axis=0), temp_growth])\n",
    "    return res\n",
    "\n",
    "# def get_estimates(\n",
    "#         tickers,\n",
    "#         start_date: dt.date=dt.date(1995, 1, 1), \n",
    "#         end_date: dt.date=TODAY):\n",
    "\n",
    "\n",
    "def get_price_multiples(\n",
    "        tickers: Collection[str], \n",
    "        start_date: dt.date=dt.date(2000, 1, 1), \n",
    "        end_date: dt.date=TODAY):\n",
    "    df = blp.bdh(tickers, [\"px_last\", \"best_cur_ev_to_ebitda\", \n",
    "                \"fcf_yield_with_cur_entp_val\", \"best_pe_next_ear\",\n",
    "                \"px_to_book_ratio\", \"px_to_sales_ratio\"],\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                Per=\"W\", \n",
    "                )\n",
    "    df.index = df.index.astype(\"datetime64[ns]\").to_period(freq=\"W\")\n",
    "    df = df.ffill()\n",
    "    return df\n",
    "    \n",
    "def get_future_returns(ref_date: dt.date, price_df: pd.DataFrame):\n",
    "    df = price_df.copy(deep=True)\n",
    "    df.index = df.index.astype(\"datetime64[ns]\")\n",
    "    base_date_ind = df.index.to_series().lt(np.datetime64(ref_date)).sum()\n",
    "    _3m_ind = df.index.to_series().lt(np.datetime64(ref_date + dt.timedelta(days=90))).sum()\n",
    "    _6m_ind = df.index.to_series().lt(np.datetime64(ref_date + dt.timedelta(days=180))).sum()\n",
    "    _1yr_ind = df.index.to_series().lt(np.datetime64(ref_date + dt.timedelta(days=365))).sum()\n",
    "    _3yr_ind = df.index.to_series().lt(np.datetime64(ref_date + dt.timedelta(days=365 * 3))).sum()\n",
    "    base_price = df.iloc[base_date_ind]\n",
    "    _3m_returns= (df.iloc[ _3m_ind - 5 : _3m_ind + 5] / base_price).mean()\n",
    "    # _3m_returns_std = (df.iloc[ _3m_ind - 5 : _3m_ind + 5] / base_price).std()\n",
    "    _6m_returns = (df.iloc[ _6m_ind - 10 : _6m_ind + 10] / base_price).mean()\n",
    "    _1yr_returns = (df.iloc[ _1yr_ind - 20 : _1yr_ind + 20] / base_price).mean()\n",
    "    _3yr_returns = (df.iloc[ _3yr_ind - 60 : _3yr_ind + 60] / base_price).mean()\n",
    "    res = pd.concat([_3m_returns, _6m_returns, _1yr_returns, _3yr_returns], axis=1)\n",
    "    res.columns = [\"3m\", \"6m\", \"1yr\", \"3yr\"]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p.peng\\AppData\\Local\\Temp\\ipykernel_17916\\3596706963.py:19: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  hist_financials = hist_financials.reset_index().groupby(\"year\").mean().stack()\\\n",
      "C:\\Users\\p.peng\\AppData\\Local\\Temp\\ipykernel_17916\\3596706963.py:32: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  res = pd.concat([hist_financials.drop(\"is_fields\", axis=0), temp_growth])\n"
     ]
    }
   ],
   "source": [
    "hist_financial_data = get_hist_financials(training_desc.ID_BB_GLOBAL)\n",
    "hist_financial_data.to_csv(\"historical_financial_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = get_price_multiples(training_desc.ID_BB_GLOBAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.to_csv(\"price_multiples.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Organizing data for SQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universe = pd.read_csv(\"./datafiles/impax_universe_all.csv\", \n",
    "#                        header=[0], index_col=[0], low_memory=False)\n",
    "# financial_data = pd.read_csv(\"./datafiles/historical_financial_data.csv\", \n",
    "#                              header=[0,1], index_col=[0,1])\n",
    "# financial_data_forsql = financial_data.T\n",
    "# financial_data_forsql.columns = financial_data_forsql.columns.get_level_values(1)\n",
    "# financial_data_forsql.reset_index().to_csv(\n",
    "#     \"./datafiles/historical_financial_data_sql.csv\",\n",
    "#     index=False)\n",
    "price_multiples = pd.read_csv(\"./datafiles/price_multiples.csv\", \n",
    "                             header=[0,1], index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.chdir(\"../\")\n",
    "sys.path.append('c:\\\\Users\\\\p.peng\\\\StockEncoder')\n",
    "from utils.database import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "price_multiples.index.names = [\"period\"]\n",
    "price_multiples.columns.names = [\"figi\", \"field\"]\n",
    "price_multiples_pivot = price_multiples\\\n",
    "    .unstack().to_frame(\"value\")\\\n",
    "        .pivot_table(index=[\"figi\", \"period\"], columns=[\"field\"], aggfunc=\"mean\")  # remove duplicates by averaging\n",
    "price_multiples_pivot.columns = price_multiples_pivot.columns.get_level_values(1)\n",
    "price_multiples_pivot = price_multiples_pivot.reset_index()\n",
    "price_multiples_pivot[\"period\"] = price_multiples_pivot.period.apply(\n",
    "    lambda x: dt.datetime.strptime(x.split(\"/\")[-1], \"%Y-%m-%d\")).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_multiples_pivot = price_multiples_pivot\\\n",
    "            .replace(float(\"inf\"), np.nan)\\\n",
    "            .replace(float(\"-inf\"), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trouble shooting\n",
    "\n",
    "# price_multiples_pivot\\\n",
    "#             .replace(float(\"inf\"), np.nan)\\\n",
    "#             .replace(float(\"-inf\"), np.nan)\\\n",
    "#             .iloc[(i+1) * chunk_size - 1 : (i+1) * chunk_size].to_sql( \n",
    "#             \"price_multiples_stock_encoder\", \n",
    "#             index=False, \n",
    "#             if_exists=\"append\",\n",
    "#             con=sql_engine\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/78712 [00:46<503:12:18, 23.02s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import threading\n",
    "import json\n",
    "\n",
    "\n",
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout(seconds):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            res = [TimeoutException('function timeout')]\n",
    "            def target(result, *args, **kwargs):\n",
    "                try:\n",
    "                    result[0] = func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    result[0] = e\n",
    "            thread = threading.Thread(target=target, args=(res,)+args, kwargs=kwargs)\n",
    "            thread.start()\n",
    "            thread.join(seconds)\n",
    "            if isinstance(res[0], BaseException):\n",
    "                raise res[0]\n",
    "            return res[0]\n",
    "        return wrapper\n",
    "\n",
    "def timeout_no_return_func(seconds):\n",
    "    \"\"\"timeout decorator for functions that returns None\"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            res = [TimeoutException('function timeout')]\n",
    "            def target(result, *args, **kwargs):\n",
    "                try:\n",
    "                    func(*args, **kwargs)\n",
    "                    result[0] = None  # Explicitly set result to None if function doesn't return anything\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    result[0] = e\n",
    "            thread = threading.Thread(target=target, args=(res,)+args, kwargs=kwargs)\n",
    "            thread.start()\n",
    "            thread.join(seconds)\n",
    "            if isinstance(res[0], BaseException):\n",
    "                raise res[0]\n",
    "            return res[0]\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "sql = SQLDatabase()\n",
    "sql_engine = sql.engine\n",
    "chunk_size = 50\n",
    "last_i = 101\n",
    "if f\"passed_price_multiple_index_chunksize={chunk_size}.json\" in os.listdir(\"./data\"):\n",
    "    passed_i = json.load(open(f\"./data/passed_price_multiple_index_chunksize={chunk_size}.json\", \"r\"))\n",
    "else:\n",
    "    passed_i = []\n",
    "# price_multiples_pivot\\\n",
    "#     .replace(float(\"inf\"), np.nan)\\\n",
    "#     .replace(float(\"-inf\"), np.nan)\\\n",
    "#     .iloc[: chunk_size]\\\n",
    "#     .to_sql(\n",
    "#     \"price_multiples_stock_encoder\", \n",
    "#     index=False, \n",
    "#     if_exists=\"replace\", # 1st write, need to replace\n",
    "#     con=sql_engine\n",
    "#     )\n",
    "\n",
    "@timeout_no_return_func(15)\n",
    "def load_chunk_to_sql(i: int):\n",
    "    if (i + 1) * chunk_size <= len(price_multiples) - 1:\n",
    "        price_multiples_pivot\\\n",
    "            .iloc[(i)*chunk_size : (i+1) * chunk_size]\\\n",
    "            .to_sql( \n",
    "            \"price_multiples_stock_encoder\", \n",
    "            index=False, \n",
    "            if_exists=\"append\",\n",
    "            con=sql_engine\n",
    "            )\n",
    "    else:\n",
    "        price_multiples_pivot\\\n",
    "            .iloc[(i)*chunk_size : ]\\\n",
    "            .to_sql(\n",
    "            \"price_multiples_stock_encoder\", \n",
    "            index=False, \n",
    "            if_exists=\"append\",\n",
    "            con=sql_engine\n",
    "            )\n",
    "    return True\n",
    "\n",
    "for i in tqdm(range(last_i, len(price_multiples_pivot) // chunk_size)):\n",
    "    try:\n",
    "        load_chunk_to_sql(i)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    passed_i.append(i)\n",
    "    json.dump(passed_i, open(f\"./data/passed_price_multiple_index_chunksize={chunk_size}.json\", \"w\"))\n",
    "    last_i = i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = pd.read_csv(\"impax_universe_all.csv\", header=[0], index_col=[0], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_data = pd.read_csv(\"historical_financial_data.csv\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asia_dd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
