{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train macro & fundamental-aware price models \n",
    "Pretraining with fundamental, macroeconomic, estimate and sharep price data to capture the data patterns.\n",
    "Use embedded fundamental/macro/short-term information for return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import FundamentalDataset, PriceDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import itertools\n",
    "from utils import Defaults\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "DEFAULTS = Defaults\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "fund_data = FundamentalDataset()\n",
    "fund_data_weekly = FundamentalDataset(freq=\"W\")\n",
    "price_data = PriceDataset()\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data_ls, masks = [], []\n",
    "    for data, mask in batch:\n",
    "        data_ls.append(data)\n",
    "        masks.append(mask)\n",
    "    return (\n",
    "        torch.stack(data_ls),\n",
    "        torch.stack(masks)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train autoencoders as pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Train encoders on fundamental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "def expand_mask(mask: torch.tensor, target_dim: int) -> torch.tensor:\n",
    "    \"\"\"expand mask from n dimensions to n+1 dimensions\"\"\"\n",
    "    newmask = deepcopy(mask).unsqueeze(-1)\n",
    "    mask_dims = list(newmask.shape)\n",
    "    mask_dims[-1] = target_dim\n",
    "    mask_dims = tuple(mask_dims)\n",
    "    return newmask.expand(mask_dims)\n",
    "\n",
    "def expand_masks(masks: Sequence[torch.tensor], target_dims: Sequence[int]):\n",
    "    expanded_masks = []\n",
    "    for mask, dim in zip(masks, target_dims):\n",
    "        newmask = expand_mask(mask, dim)\n",
    "        expanded_masks.append(newmask)\n",
    "    return expanded_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(\n",
    "        input: torch.tensor, \n",
    "        target: torch.tensor,\n",
    "        mask: torch.tensor,\n",
    "        na_pad: torch.tensor,\n",
    "        ) -> torch.tensor:\n",
    "    \"\"\"custome MSE loss to mask padding & nan values\n",
    "    :param input: original vector\n",
    "    :param target: target vector\n",
    "    :param \n",
    "    \"\"\"\n",
    "    loss = nn.MSELoss()\n",
    "    dims = input.shape[-1]\n",
    "    na_mask = input == na_pad\n",
    "    expanded_mask = expand_mask(mask, dims)\n",
    "    new_mask = na_mask.astype(torch.bool) + expanded_mask.astype(torch.bool)\n",
    "    masked_input = torch.masked_select(input, ~new_mask) # mask itself is True if masked\n",
    "    masked_target = torch.masked_select(target, ~new_mask)\n",
    "    return loss(masked_input, masked_target)\n",
    "\n",
    "def composite_mseloss(mse_losses: Sequence[torch.tensor]):\n",
    "    mean_loss = torch.mean(mse_losses)\n",
    "    penalty_loss = torch.sum([(loss - mean_loss)**2 for loss in mse_losses])\n",
    "    composite_loss = mean_loss + penalty_loss\n",
    "    return composite_loss\n",
    "\n",
    "def multiple_input_masked_mse_loss(\n",
    "        inputs: Sequence[torch.tensor],\n",
    "        targets: Sequence[torch.tensor],\n",
    "        masks: Sequence[torch.tensor],\n",
    "        na_pads: Sequence[torch.tensor]):\n",
    "    losses = []\n",
    "    for input, target, mask, na_pad in zip(\n",
    "        inputs, targets, masks, na_pads):\n",
    "        loss = masked_mse_loss(input, target, mask, na_pad)\n",
    "        losses.append(loss)\n",
    "    composite_loss = composite_mseloss(losses)\n",
    "    return composite_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): BatchNorm1d(170, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Linear(in_features=170, out_features=42, bias=True)\n",
      "  (3): Linear(in_features=42, out_features=10, bias=True)\n",
      "  (4): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (5): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.linear_encoder_layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3])\n",
      "torch.Size([16, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "from typing import Sequence, Tuple, Optional\n",
    "def encode(\n",
    "        model, \n",
    "        inputs: Sequence[Tuple[torch.tensor, Optional[torch.tensor]]],\n",
    "        padding_masks: Sequence[torch.tensor]\n",
    "        ) -> Tuple[torch.tensor, Tuple[torch.tensor]]:\n",
    "    \"\"\"encode a list of inputs of different lengths and dimensionalities\n",
    "    into a single embedding vector\n",
    "    \"\"\"\n",
    "    embeddings, memories = [], []\n",
    "    for input, mask, transformer_encoder, linear_encoder in zip(\n",
    "        inputs, padding_masks, model.transformer_encoders, model.linear_encoder_layers):\n",
    "        x_ = transformer_encoder(input, src_key_padding_mask=mask)\n",
    "        memories.append(x_)\n",
    "        embedded = linear_encoder(x_)\n",
    "        print(embedded.shape)\n",
    "        embeddings.append(embedded)\n",
    "    _embedding = torch.stack(embeddings, dim=-1)\n",
    "    print(_embedding.shape)\n",
    "    embedding = model.linear_encoder(_embedding)\n",
    "    embedding = model.tanh(embedding)\n",
    "    return (embedding, memories)\n",
    "\n",
    "embedding, memories = encode(model, [input], [mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decode(embedding, memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x3 and 1x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28minput\u001b[39m, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(DEVICE), mask\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 2\u001b[0m embedding, memories \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode(embedding, memories)\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/timeseries-t4/code/users/p.peng/stockencoder/models/autoencoder.py:115\u001b[0m, in \u001b[0;36mBaseAutoEncoder.encode\u001b[0;34m(self, inputs, padding_masks)\u001b[0m\n\u001b[1;32m    113\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(embedded)\n\u001b[1;32m    114\u001b[0m _embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(embeddings, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtanh(embedding)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (embedding, memories)\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x3 and 1x3)"
     ]
    }
   ],
   "source": [
    "input, mask = input.to(DEVICE), mask.to(DEVICE)\n",
    "embedding, memories = model.encode([input], [mask])\n",
    "output = model.decode(embedding, memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x3 and 1x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (\u001b[38;5;28minput\u001b[39m, mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fundamental_data_loader):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28minput\u001b[39m, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(DEVICE), mask\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 46\u001b[0m     embedding, memories \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode(embedding, memories)\n\u001b[1;32m     48\u001b[0m     loss \u001b[38;5;241m=\u001b[39m masked_mse_loss(\u001b[38;5;28minput\u001b[39m, output, mask, na_pad\u001b[38;5;241m=\u001b[39mDEFAULTS\u001b[38;5;241m.\u001b[39mpadding_val)\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/timeseries-t4/code/users/p.peng/stockencoder/models/autoencoder.py:115\u001b[0m, in \u001b[0;36mBaseAutoEncoder.encode\u001b[0;34m(self, inputs, padding_masks)\u001b[0m\n\u001b[1;32m    113\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(embedded)\n\u001b[1;32m    114\u001b[0m _embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(embeddings, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtanh(embedding)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (embedding, memories)\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x3 and 1x3)"
     ]
    }
   ],
   "source": [
    "from models.autoencoder import BaseAutoEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "RUN = 1\n",
    "LR = 1e-4\n",
    "NUM_TRANSFORMER_LAYERS = 5\n",
    "WINDOW_SIZE = 10\n",
    "NHEADS = 1\n",
    "ENCODING_DIM = 3\n",
    "MAX_EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "logger_stem = \"./traininglog/fundamental_encoder/runs/\"\n",
    "logger = SummaryWriter(f\"{logger_stem}run{RUN};lr={LR};notflayrs={NUM_TRANSFORMER_LAYERS};wd={WINDOW_SIZE};nh={NHEADS};edim={ENCODING_DIM};bsize={BATCH_SIZE}\")\n",
    "\n",
    "fundamental_data_loader = DataLoader(\n",
    "    fund_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=BATCH_SIZE\n",
    ")\n",
    "\n",
    "num_batches = len(fundamental_data_loader)\n",
    "\n",
    "model = BaseAutoEncoder(\n",
    "    window_sizes=[WINDOW_SIZE],\n",
    "    encoding_dim=ENCODING_DIM, \n",
    "    num_transformer_layers=[NUM_TRANSFORMER_LAYERS], \n",
    "    dims=[17],\n",
    "    activation_func=F.tanh,\n",
    "    nheads=[NHEADS],\n",
    "    device=DEVICE)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=LR, betas=[0.9, 0.99], eps=1e-07)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    running_losses = []\n",
    "    for i, (input, mask) in enumerate(fundamental_data_loader):\n",
    "        # forward pass\n",
    "        input, mask = input.to(DEVICE), mask.to(DEVICE)\n",
    "        embedding, memories = model.encode([input], [mask])\n",
    "        output = model.decode(embedding, memories)\n",
    "        loss = masked_mse_loss(input, output, mask, na_pad=DEFAULTS.padding_val)\n",
    "        running_losses.append(loss.item())\n",
    "        logger.add_scaler(\"loss/train_step\", loss.item(), step=epoch*num_batches + i)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_loss = np.mean(running_losses)\n",
    "    logger.add_scalar(\"loss/train\", mean_loss, step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.linear_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-2.7758e-02,  1.7303e-03,  1.6838e+00, -1.1760e+00,  1.5005e+00,\n",
       "           -1.3603e+00,  1.0560e+00, -5.9297e-01, -1.4075e+00, -1.1499e+00,\n",
       "            9.4779e-01,  1.0356e+00, -9.9712e-01,  6.9963e-01, -1.0088e-01,\n",
       "            4.1064e-01, -5.2325e-01],\n",
       "          [-5.6339e-01, -6.8779e-02,  6.0846e-01, -1.1481e+00,  6.5743e-01,\n",
       "            1.6345e+00,  3.5085e-01, -2.3056e+00, -1.0169e+00,  1.3147e+00,\n",
       "            7.5867e-01,  2.5464e-01, -5.2802e-01,  1.1613e+00, -1.1111e+00,\n",
       "           -2.9937e-01,  3.0079e-01],\n",
       "          [ 3.4619e-01,  1.8169e+00, -1.0665e+00,  4.0032e-01,  5.3362e-01,\n",
       "            6.3245e-01,  8.5335e-01, -1.3895e+00,  3.8059e-01, -1.2566e+00,\n",
       "           -8.7481e-01,  1.5971e-01, -5.6410e-01,  8.6297e-01, -1.6452e+00,\n",
       "           -6.7243e-01,  1.4831e+00],\n",
       "          [ 5.5835e-01,  1.9708e+00, -8.1471e-02, -9.1841e-01, -3.0379e-02,\n",
       "            2.9579e-01, -1.9699e+00, -6.5844e-01, -2.8596e-01, -1.1177e+00,\n",
       "            1.4016e+00, -4.0935e-01,  1.8460e+00, -2.0818e-01, -4.8743e-01,\n",
       "            4.9115e-01, -3.9653e-01],\n",
       "          [ 2.9369e-01,  2.7053e-01, -8.5254e-01,  1.6282e+00, -3.3637e-01,\n",
       "            9.1920e-01,  7.3759e-01, -2.3617e+00,  5.9778e-01, -1.5162e-01,\n",
       "           -5.0009e-01, -1.1749e-01,  9.2485e-02,  1.8460e+00, -7.7928e-01,\n",
       "            2.2355e-02, -1.3088e+00],\n",
       "          [-5.7297e-01,  7.2605e-01,  2.4146e+00, -6.6858e-02,  7.5335e-01,\n",
       "            9.2700e-01, -7.0041e-01,  5.8145e-01, -8.6874e-01, -6.4770e-01,\n",
       "            1.0598e+00, -8.7714e-01, -3.5472e-01, -3.4865e-01,  6.9670e-01,\n",
       "           -1.8849e+00, -8.3684e-01],\n",
       "          [ 1.4438e+00,  6.9790e-01,  3.1972e-01, -5.2516e-01,  1.8552e-01,\n",
       "            1.8656e+00,  6.9544e-02, -1.4465e+00,  1.7178e-01, -9.2682e-01,\n",
       "            1.5338e+00, -2.8104e-01, -6.4450e-01,  5.4229e-01, -6.5902e-02,\n",
       "           -1.6712e+00, -1.2688e+00],\n",
       "          [-6.2889e-01, -1.1046e+00, -7.4582e-01, -4.6241e-01, -2.4789e-01,\n",
       "            1.6904e+00, -6.4828e-01, -4.7667e-02, -1.8289e-03,  8.5733e-01,\n",
       "           -2.3965e-01,  1.0083e+00,  1.2000e+00,  1.7119e+00,  5.1583e-01,\n",
       "           -2.0387e+00, -8.1795e-01],\n",
       "          [-6.4051e-01,  1.0767e+00,  9.0124e-01,  6.0824e-02,  2.1082e+00,\n",
       "           -6.6595e-01, -7.9293e-02, -7.0894e-01,  8.9692e-01, -9.5097e-01,\n",
       "           -1.2524e+00,  1.0740e+00,  1.2837e+00, -7.4158e-01, -5.9496e-01,\n",
       "           -3.0382e-01, -1.4632e+00],\n",
       "          [-2.3188e+00,  1.7529e+00, -2.4150e-01, -7.3873e-01,  7.9179e-01,\n",
       "           -6.7482e-01,  1.3114e+00, -1.0125e+00,  6.9352e-02,  9.9071e-01,\n",
       "            1.0815e+00, -1.1250e-01, -3.8677e-01, -7.2664e-01,  9.6574e-01,\n",
       "           -2.0668e-01, -5.4442e-01]],\n",
       " \n",
       "         [[-1.1402e-01,  3.6745e-01, -4.9760e-01,  7.3598e-01, -8.4470e-01,\n",
       "            2.1535e+00, -8.8877e-01, -1.5828e+00,  1.4330e+00,  6.0127e-01,\n",
       "           -1.1928e+00, -8.5472e-01,  1.2260e+00, -6.1287e-01,  4.8285e-01,\n",
       "            3.6409e-01, -7.7583e-01],\n",
       "          [ 4.6870e-01,  2.6897e-01,  5.1105e-01,  2.2435e-01,  5.4595e-01,\n",
       "           -1.2578e+00, -4.1729e-01,  8.5795e-01,  1.2204e+00, -2.1091e+00,\n",
       "           -8.3233e-01, -9.7095e-02,  1.0719e+00, -8.7528e-01,  1.3047e+00,\n",
       "            7.7308e-01, -1.6581e+00],\n",
       "          [-7.5714e-01, -1.3928e+00,  1.5063e+00, -5.6230e-01,  9.5351e-01,\n",
       "            1.2033e-01, -2.8729e-01, -8.0342e-01, -2.8376e-01,  6.5748e-01,\n",
       "            6.6709e-01, -1.2449e-01,  6.8211e-01, -7.1664e-01,  1.5129e+00,\n",
       "            1.0450e+00, -2.2169e+00],\n",
       "          [-1.0723e+00, -1.4449e+00,  1.1803e+00, -1.9144e-01,  6.2784e-01,\n",
       "            2.3648e-01,  2.5377e+00,  2.3086e-01,  6.0340e-03,  5.7099e-01,\n",
       "           -1.4661e+00,  1.6935e-02, -1.2609e+00,  7.9371e-01, -8.2215e-02,\n",
       "            1.3363e-01, -8.1677e-01],\n",
       "          [-1.2862e+00,  3.4219e-01,  1.8949e+00, -1.9857e+00,  1.4853e+00,\n",
       "           -2.4214e-02,  1.6149e-02,  8.3728e-02, -1.1170e+00, -3.0301e-02,\n",
       "            4.9034e-01,  1.5929e-01,  8.8916e-02, -1.6144e+00,  1.0793e+00,\n",
       "            4.3071e-01, -1.3118e-02],\n",
       "          [-3.8414e-01, -4.2101e-01, -1.1515e+00, -1.0376e+00,  3.7514e-01,\n",
       "           -1.7795e-01,  7.6087e-01, -1.8827e+00,  1.8962e-01,  2.4859e-01,\n",
       "           -9.0257e-01,  1.3158e+00,  1.0127e-01,  4.1503e-01, -2.8686e-01,\n",
       "            2.6518e+00,  1.8623e-01],\n",
       "          [-1.9907e+00, -1.3151e-03,  3.0718e-01, -1.0949e-01,  7.4711e-01,\n",
       "           -1.3794e+00,  2.4117e-01, -4.7673e-01, -6.6908e-01,  1.2556e-01,\n",
       "           -1.4905e+00,  6.3429e-01,  1.2195e+00, -4.0367e-01,  2.6609e-01,\n",
       "            2.1735e+00,  8.0653e-01],\n",
       "          [-1.6868e-01,  1.0076e+00,  1.8255e+00, -5.3864e-01,  1.2323e+00,\n",
       "           -9.8248e-01,  7.2310e-01, -1.8888e+00, -5.9840e-01, -5.7300e-01,\n",
       "            2.4037e-01, -8.2697e-01, -4.7613e-01, -7.2448e-01,  1.0110e-01,\n",
       "            1.8751e+00, -2.2751e-01],\n",
       "          [-3.6395e-01, -1.3173e+00,  2.4608e-01, -9.2065e-01, -1.0652e+00,\n",
       "            1.4862e+00,  3.0189e-01,  2.0717e-01, -1.5225e+00,  4.4122e-01,\n",
       "            1.0762e+00, -1.0061e+00, -1.4317e+00,  1.3263e+00,  8.3679e-01,\n",
       "            1.0746e+00,  6.3093e-01],\n",
       "          [ 1.5152e+00, -1.4723e+00,  1.2967e+00,  5.9667e-01, -1.7008e-01,\n",
       "            1.3830e+00, -9.6473e-01, -7.1846e-01, -4.2119e-01, -1.7013e+00,\n",
       "           -1.2743e+00,  1.6914e-01,  6.7570e-01,  1.0150e+00, -6.9763e-01,\n",
       "            6.2408e-01,  1.4454e-01]],\n",
       " \n",
       "         [[ 2.7598e-01, -4.3412e-01, -9.2687e-01,  8.0922e-01, -9.0210e-01,\n",
       "            1.6377e+00, -9.4879e-01, -9.9281e-01,  1.7989e+00,  4.9931e-01,\n",
       "           -1.3866e+00, -6.7707e-01,  1.5589e+00, -7.0018e-01,  7.8958e-01,\n",
       "            2.1605e-01, -6.1713e-01],\n",
       "          [ 3.7243e-01,  2.3173e-01,  3.4477e-01,  5.9864e-01,  6.6162e-01,\n",
       "           -1.1359e+00, -3.4288e-01,  1.0741e+00,  4.8526e-01, -2.3573e+00,\n",
       "           -6.9620e-01,  1.9839e-01,  1.3004e+00, -9.6283e-01,  1.0672e+00,\n",
       "            7.8523e-01, -1.6246e+00],\n",
       "          [-1.0676e+00, -1.3043e+00,  9.8788e-01, -7.5217e-01,  3.8088e-01,\n",
       "           -1.9268e-01, -4.5575e-01, -2.8429e-01, -9.6175e-02,  5.9003e-01,\n",
       "            1.0625e+00, -1.0949e-02,  9.2191e-01, -3.6874e-02,  1.8694e+00,\n",
       "            7.7739e-01, -2.3892e+00],\n",
       "          [-1.0660e+00, -1.3692e+00,  5.3078e-01, -4.9287e-02,  6.4425e-01,\n",
       "            3.5626e-01,  2.7275e+00, -3.9254e-01,  1.3314e-03,  6.8613e-01,\n",
       "           -1.6605e+00,  1.6319e-01, -1.0323e+00,  8.7153e-01,  1.2946e-01,\n",
       "            1.3258e-01, -6.7322e-01],\n",
       "          [-1.0934e+00,  3.0437e-01,  1.4776e+00, -1.9762e+00,  1.1650e+00,\n",
       "           -6.0789e-01, -4.1129e-01,  4.3485e-01, -8.9926e-01,  1.2914e-01,\n",
       "            1.0827e+00,  2.3116e-01, -2.0534e-01, -1.8820e+00,  1.0126e+00,\n",
       "            8.5332e-01,  3.8477e-01],\n",
       "          [ 1.9481e-02, -4.0797e-01, -1.5159e+00, -9.0917e-01,  1.2489e-01,\n",
       "           -3.2587e-01,  6.2457e-01, -2.1255e+00,  4.5715e-01,  2.9907e-01,\n",
       "           -8.2339e-01,  1.2421e+00,  3.9645e-01,  4.2402e-01, -2.1315e-01,\n",
       "            2.3768e+00,  3.5642e-01],\n",
       "          [-2.0913e+00, -2.5703e-01, -1.9186e-01, -4.8077e-02,  5.6029e-01,\n",
       "           -1.3366e+00,  2.2424e-01,  6.8129e-02, -4.3459e-01,  1.5706e-01,\n",
       "           -1.7998e+00,  8.1452e-01,  1.0287e+00, -1.7971e-01,  7.5493e-01,\n",
       "            2.0205e+00,  7.1062e-01],\n",
       "          [-5.5088e-01,  9.7728e-01,  1.8696e+00, -3.8753e-01,  1.0595e+00,\n",
       "           -4.0742e-01,  9.8683e-01, -2.0216e+00, -5.4493e-01, -6.5904e-01,\n",
       "            2.5688e-01, -6.5498e-01, -1.8147e-01, -1.0537e+00, -2.1802e-02,\n",
       "            1.7815e+00, -4.4820e-01],\n",
       "          [ 3.7320e-01, -1.3151e+00, -3.5057e-01, -6.0499e-01, -1.5366e+00,\n",
       "            1.2673e+00,  2.5614e-01, -8.9962e-02, -1.3307e+00,  3.3728e-01,\n",
       "            1.0543e+00, -1.1842e+00, -1.0481e+00,  1.7528e+00,  1.0245e+00,\n",
       "            7.6199e-01,  6.3261e-01],\n",
       "          [ 1.5715e+00, -1.4659e+00,  1.2510e+00,  2.1522e-01, -1.4336e-01,\n",
       "            1.1566e+00, -8.7869e-01, -9.1431e-01, -7.6703e-01, -1.7203e+00,\n",
       "           -1.0386e+00,  1.2290e-01,  1.1668e+00,  1.0468e+00, -4.9070e-01,\n",
       "            6.2860e-01,  2.5946e-01]],\n",
       " \n",
       "         [[ 3.9609e-01,  1.7075e-01, -1.1230e+00,  7.2175e-01, -1.1160e+00,\n",
       "            1.8890e+00, -8.7987e-01, -9.4218e-01,  1.4067e+00,  4.7871e-01,\n",
       "           -1.3907e+00, -8.2895e-01,  1.6384e+00, -7.9209e-01,  5.6649e-01,\n",
       "            9.4355e-02, -2.8949e-01],\n",
       "          [ 5.6076e-01,  4.0256e-01,  2.8493e-01,  3.6055e-01,  4.0899e-01,\n",
       "           -1.1537e+00, -2.0805e-01,  1.0935e+00,  8.0767e-01, -2.0653e+00,\n",
       "           -1.1872e+00,  4.7959e-02,  1.1220e+00, -8.8408e-01,  1.6290e+00,\n",
       "            3.4046e-01, -1.5601e+00],\n",
       "          [-3.9976e-01, -1.4125e+00,  6.6949e-01, -9.3529e-01,  2.8369e-01,\n",
       "           -4.7525e-01, -2.1144e-01, -2.9224e-01, -2.1432e-01,  1.2926e+00,\n",
       "            8.7617e-01, -1.3334e-01,  9.1843e-01, -5.6203e-01,  1.7430e+00,\n",
       "            1.1185e+00, -2.2656e+00],\n",
       "          [-6.7611e-01, -1.5549e+00,  3.7749e-01, -1.4185e-01,  1.2489e-01,\n",
       "            2.5302e-01,  3.0208e+00, -5.2276e-01,  1.5543e-01,  6.2996e-01,\n",
       "           -1.2254e+00,  3.4278e-01, -1.1759e+00,  7.6723e-01,  2.4327e-01,\n",
       "            2.3546e-02, -6.4154e-01],\n",
       "          [-5.2707e-01,  5.8846e-01,  1.5034e+00, -1.8306e+00,  6.8422e-01,\n",
       "           -4.8123e-01, -4.8924e-01,  1.1731e+00, -8.8516e-01, -5.0791e-01,\n",
       "            7.1947e-01,  1.2038e-02,  4.1588e-01, -2.2591e+00,  1.0190e+00,\n",
       "            7.4840e-01,  1.1633e-01],\n",
       "          [-3.1382e-02, -1.1028e-01, -1.5042e+00, -1.0186e+00,  1.2181e-01,\n",
       "           -4.7930e-01,  4.9012e-01, -2.1939e+00,  3.6599e-01,  1.1990e-01,\n",
       "           -6.2460e-01,  1.1700e+00,  8.7222e-01,  1.9485e-01, -1.3076e-01,\n",
       "            2.3436e+00,  4.1451e-01],\n",
       "          [-1.6395e+00, -7.0353e-02, -1.5015e-01, -1.2885e-01,  4.2041e-01,\n",
       "           -1.6727e+00,  2.2459e-01, -4.8715e-01, -3.9856e-01,  7.6016e-02,\n",
       "           -1.6217e+00,  8.6780e-01,  1.2007e+00, -2.1591e-01,  4.1035e-01,\n",
       "            2.1958e+00,  9.8907e-01],\n",
       "          [ 1.0249e-02,  7.9017e-01,  1.7187e+00, -1.2292e-01,  7.3891e-01,\n",
       "           -4.9142e-01,  8.8520e-01, -1.9686e+00, -4.6925e-01, -9.1871e-01,\n",
       "            3.5318e-01, -8.0541e-01, -6.2297e-01, -1.0616e+00,  3.2726e-01,\n",
       "            2.0752e+00, -4.3802e-01],\n",
       "          [ 4.2923e-01, -1.1237e+00, -4.8221e-01, -6.8008e-01, -1.7808e+00,\n",
       "            8.3291e-01,  1.0873e-01,  2.5833e-01, -1.4001e+00,  4.6763e-01,\n",
       "            1.3701e+00, -1.1715e+00, -9.4226e-01,  1.5300e+00,  8.6044e-01,\n",
       "            7.3767e-01,  9.8561e-01],\n",
       "          [ 1.6228e+00, -1.2408e+00,  1.2526e+00,  2.0313e-01, -3.2571e-01,\n",
       "            1.1996e+00, -1.1410e+00, -6.0899e-01, -4.9424e-01, -1.7324e+00,\n",
       "           -1.2957e+00,  1.1922e-01,  1.3696e+00,  6.8812e-01, -4.7308e-01,\n",
       "            6.7132e-01,  1.8550e-01]],\n",
       " \n",
       "         [[-4.3456e-02, -4.3633e-02,  1.3654e+00, -1.0655e+00,  1.2195e+00,\n",
       "           -1.2495e+00,  1.2496e+00, -5.1278e-01, -1.2213e+00, -1.4332e+00,\n",
       "            9.4629e-01,  1.1644e+00, -1.3141e+00,  1.1406e+00, -3.0963e-01,\n",
       "            3.6623e-01, -2.5910e-01],\n",
       "          [-3.6354e-01, -1.1861e-01,  6.4188e-02, -1.3533e+00,  2.2797e-01,\n",
       "            1.5757e+00, -3.0659e-02, -2.2534e+00, -6.9741e-01,  1.6672e+00,\n",
       "            7.9837e-01, -9.1299e-02, -3.0255e-01,  1.6089e+00, -6.8683e-01,\n",
       "           -4.3377e-01,  3.8904e-01],\n",
       "          [ 3.6972e-01,  1.4290e+00, -8.2331e-01,  8.1108e-01, -2.2321e-01,\n",
       "            8.6740e-01,  3.3898e-01, -1.3413e+00,  1.8522e-01, -9.6606e-01,\n",
       "           -1.0821e+00, -2.3794e-02, -4.0199e-01,  8.4892e-01, -1.5470e+00,\n",
       "           -6.5935e-01,  2.2177e+00],\n",
       "          [ 6.8890e-01,  1.5124e+00,  1.3850e-01, -4.8068e-01, -2.2959e-01,\n",
       "            4.7339e-01, -2.7413e+00, -1.0644e+00,  1.4574e-01, -7.6809e-01,\n",
       "            1.0541e+00, -1.8430e-01,  1.7970e+00, -1.2209e-01, -9.2017e-02,\n",
       "            8.5719e-02, -2.1325e-01],\n",
       "          [ 8.0682e-01,  3.5314e-02, -1.4082e+00,  2.1045e+00, -6.4744e-01,\n",
       "            8.7042e-01,  1.5734e-01, -1.7076e+00,  6.9046e-01,  1.1683e-01,\n",
       "           -7.7900e-01, -3.2527e-01, -4.8580e-02,  1.8511e+00, -7.8651e-01,\n",
       "           -2.0675e-01, -7.2344e-01],\n",
       "          [-3.2761e-01,  5.8787e-01,  1.9748e+00,  6.5855e-01,  5.0862e-01,\n",
       "            9.1934e-01, -1.6139e-01,  1.1447e+00, -7.2636e-01, -1.1330e+00,\n",
       "            3.4015e-01, -5.8334e-01, -2.6680e-01, -3.3192e-01,  9.2764e-01,\n",
       "           -2.1026e+00, -1.4287e+00],\n",
       "          [ 1.6104e+00,  3.5820e-01,  3.9008e-01, -2.8001e-01, -4.8880e-01,\n",
       "            2.3650e+00, -2.2627e-01, -9.0704e-01,  4.6540e-01, -1.0692e+00,\n",
       "            9.2690e-01, -3.4205e-01, -7.8954e-01,  6.6199e-01,  5.6808e-02,\n",
       "           -1.6879e+00, -1.0440e+00],\n",
       "          [ 2.3131e-01, -1.0831e+00, -1.3864e+00,  1.3115e-01, -6.6940e-01,\n",
       "            1.6528e+00, -1.3369e+00,  4.9943e-01,  6.6705e-01, -6.5748e-02,\n",
       "           -5.5632e-01,  8.5161e-01,  8.3099e-01,  1.4898e+00,  5.7199e-01,\n",
       "           -1.9685e+00,  1.4017e-01],\n",
       "          [-1.4040e-01,  9.9439e-01,  5.2479e-01,  6.0818e-01,  1.7635e+00,\n",
       "           -3.8618e-01, -3.9232e-01, -1.4237e+00,  1.2306e+00, -1.0556e+00,\n",
       "           -1.4521e+00,  8.4449e-01,  1.5876e+00, -9.3516e-01, -5.4532e-01,\n",
       "           -5.2710e-01, -6.9558e-01],\n",
       "          [-2.2531e+00,  1.8215e+00, -8.1739e-01, -6.0217e-01,  7.9705e-01,\n",
       "           -5.8378e-01,  1.0524e+00, -7.0900e-01,  3.6445e-01,  1.1055e+00,\n",
       "            7.9745e-01, -1.6559e-01, -1.0425e-01, -7.3325e-01,  1.1984e+00,\n",
       "           -1.9570e-01, -9.7252e-01]]], device='cuda:0',\n",
       "        grad_fn=<NativeLayerNormBackward0>)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(model, embedding, memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'is_nested'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reconstructed \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/timeseries-t4/code/users/p.peng/stockencoder/models/autoencoder.py:127\u001b[0m, in \u001b[0;36mBaseAutoEncoder.decode\u001b[0;34m(self, embedding, memories)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_inputs):\n\u001b[1;32m    126\u001b[0m     _output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_decoder_layers[i](_embeddings[i])\n\u001b[0;32m--> 127\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_decoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemories\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     reconstructed_xs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:465\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    462\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 465\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:856\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n\u001b[0;32m--> 856\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mha_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    857\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:874\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._mha_block\u001b[0;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mha_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, mem: Tensor,\n\u001b[1;32m    873\u001b[0m                attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 874\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultihead_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/activation.py:1211\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_native_multi_head_attention(\n\u001b[1;32m   1197\u001b[0m                 query,\n\u001b[1;32m   1198\u001b[0m                 key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1208\u001b[0m                 average_attn_weights,\n\u001b[1;32m   1209\u001b[0m                 mask_type)\n\u001b[0;32m-> 1211\u001b[0m any_nested \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mis_nested \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_nested\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_nested\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m any_nested, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiheadAttention does not support NestedTensor outside of its fast path. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   1213\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe fast path was not hit because \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhy_not_fast_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;66;03m# make sure that the transpose op does not affect the \"is\" property\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'is_nested'"
     ]
    }
   ],
   "source": [
    "reconstructed = model.decode(embedding, [memory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 17])\n",
      "torch.Size([10, 17])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 17 elements not 170",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 15\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(model, inputs, padding_masks)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m memories\u001b[38;5;241m.\u001b[39mappend(x_)\n\u001b[0;32m---> 15\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(embedded\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     17\u001b[0m embeddings\u001b[38;5;241m.\u001b[39mappend(embedded)\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 17 elements not 170"
     ]
    }
   ],
   "source": [
    "encode(model, batch[0].to(DEVICE), batch[1].to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(1, 1, batch_first=True)\n",
    "encoder = nn.TransformerEncoder(encoder_layer, 1)\n",
    "\n",
    "encoder(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\p.peng\\Anaconda3\\envs\\stockencoder_env\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:366: RuntimeWarning: invalid value encountered in log\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000e+10,  2.2513e-01, -1.0000e+10,  8.9167e-01,  9.5669e-01],\n",
       "        [-1.0000e+10,  2.2591e-01, -1.0000e+10,  8.9041e-01,  9.5619e-01],\n",
       "        [-1.0000e+10,  2.2721e-01, -1.0000e+10,  8.8854e-01,  9.5544e-01],\n",
       "        ...,\n",
       "        [-1.0000e+10,  2.7621e-01, -6.6862e+00,  8.8338e-01,  9.2140e-01],\n",
       "        [-1.0000e+10,  2.7616e-01, -2.5919e+00,  8.8354e-01,  9.2150e-01],\n",
       "        [-1.0000e+10,  2.7332e-01, -1.0000e+10,  8.9210e-01,  9.2715e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data[(1, dt.date(2022, 1, 1))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
