{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train macro & fundamental-aware price models \n",
    "Pretraining with fundamental, macroeconomic, estimate and sharep price data to capture the data patterns.\n",
    "Use embedded fundamental/macro/short-term information for return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import FundamentalDataset, PriceDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import itertools\n",
    "from utils import Defaults\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "DEFAULTS = Defaults\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "fund_data = FundamentalDataset()\n",
    "fund_data_weekly = FundamentalDataset(freq=\"W\")\n",
    "price_data = PriceDataset()\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data_ls, masks = [], []\n",
    "    for data, mask in batch:\n",
    "        data_ls.append(data)\n",
    "        masks.append(mask)\n",
    "    return (\n",
    "        torch.stack(data_ls),\n",
    "        torch.stack(masks)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train autoencoders as pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Train encoders on fundamental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "def expand_mask(mask: torch.tensor, target_dim: int) -> torch.tensor:\n",
    "    \"\"\"expand mask from n dimensions to n+1 dimensions\"\"\"\n",
    "    newmask = deepcopy(mask).unsqueeze(-1)\n",
    "    mask_dims = list(newmask.shape)\n",
    "    mask_dims[-1] = target_dim\n",
    "    mask_dims = tuple(mask_dims)\n",
    "    return newmask.expand(mask_dims)\n",
    "\n",
    "def expand_masks(masks: Sequence[torch.tensor], target_dims: Sequence[int]):\n",
    "    expanded_masks = []\n",
    "    for mask, dim in zip(masks, target_dims):\n",
    "        newmask = expand_mask(mask, dim)\n",
    "        expanded_masks.append(newmask)\n",
    "    return expanded_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(\n",
    "        input: torch.tensor, \n",
    "        target: torch.tensor,\n",
    "        mask: torch.tensor,\n",
    "        na_pad: torch.tensor,\n",
    "        ) -> torch.tensor:\n",
    "    \"\"\"custome MSE loss to mask padding & nan values\n",
    "    :param input: original vector\n",
    "    :param target: target vector\n",
    "    :param \n",
    "    \"\"\"\n",
    "    loss = nn.MSELoss()\n",
    "    dims = input.shape[-1]\n",
    "    na_mask = input == na_pad\n",
    "    expanded_mask = expand_mask(mask, dims)\n",
    "    new_mask = na_mask.type(torch.bool) + expanded_mask.type(torch.bool)\n",
    "    masked_input = torch.masked_select(input, ~new_mask) # mask itself is True if masked\n",
    "    masked_target = torch.masked_select(target, ~new_mask)\n",
    "    return loss(masked_input, masked_target)\n",
    "\n",
    "def composite_mseloss(mse_losses: Sequence[torch.tensor]):\n",
    "    mean_loss = torch.stack(mse_losses).sum() / len(mse_losses)\n",
    "    penalty_loss = torch.stack([(loss - mean_loss)**2 for loss in mse_losses]).sum()\n",
    "    composite_loss = mean_loss + penalty_loss\n",
    "    return composite_loss\n",
    "\n",
    "def multiple_input_masked_mse_loss(\n",
    "        inputs: Sequence[torch.tensor],\n",
    "        targets: Sequence[torch.tensor],\n",
    "        masks: Sequence[torch.tensor],\n",
    "        na_pads: Sequence[torch.tensor]):\n",
    "    losses = []\n",
    "    for input, target, mask, na_pad in zip(\n",
    "        inputs, targets, masks, na_pads):\n",
    "        loss = masked_mse_loss(input, target, mask, na_pad)\n",
    "        losses.append(loss)\n",
    "    composite_loss = composite_mseloss(losses)\n",
    "    return composite_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10, 17])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 3, 1])\n",
      "torch.Size([16, 3])\n",
      "finished encoder\n",
      "===\n",
      "\n",
      "decoder input shape: \n",
      " torch.Size([16, 3])\n",
      "after linear embedding shape:\n",
      " torch.Size([16, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "input, mask = input.to(DEVICE), mask.to(DEVICE)\n",
    "embedding, memories = encode(model, [input], [mask])\n",
    "output = decode(model, embedding, memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/anaconda/envs/stockencoder_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from models.autoencoder import BaseAutoEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "RUN = 1\n",
    "LR = 1e-4\n",
    "NUM_TRANSFORMER_LAYERS = 5\n",
    "WINDOW_SIZE = 10\n",
    "NHEADS = 1\n",
    "ENCODING_DIM = 3\n",
    "MAX_EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "logger_stem = \"./traininglog/fundamental_encoder/runs/\"\n",
    "logger = SummaryWriter(f\"{logger_stem}run{RUN};lr={LR};notflayrs={NUM_TRANSFORMER_LAYERS};wd={WINDOW_SIZE};nh={NHEADS};edim={ENCODING_DIM};bsize={BATCH_SIZE}\")\n",
    "\n",
    "fundamental_data_loader = DataLoader(\n",
    "    fund_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=BATCH_SIZE\n",
    ")\n",
    "\n",
    "num_batches = len(fundamental_data_loader)\n",
    "\n",
    "model = BaseAutoEncoder(\n",
    "    window_sizes=[WINDOW_SIZE],\n",
    "    encoding_dim=ENCODING_DIM, \n",
    "    num_transformer_layers=[NUM_TRANSFORMER_LAYERS], \n",
    "    dims=[17],\n",
    "    activation_func=F.tanh,\n",
    "    nheads=[NHEADS],\n",
    "    device=DEVICE)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=LR, betas=[0.9, 0.99], eps=1e-07)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    running_losses = []\n",
    "    for i, (input, mask) in enumerate(fundamental_data_loader):\n",
    "        # forward pass\n",
    "        input, mask = input.to(DEVICE), mask.to(DEVICE)\n",
    "        embedding, memories = model.encode([input], [mask])\n",
    "        output = model.decode(embedding, memories)\n",
    "        loss = multiple_input_masked_mse_loss([input], output, [mask], [DEFAULTS.padding_val])\n",
    "        running_losses.append(loss.item())\n",
    "        logger.add_scaler(\"loss/train_step\", loss.item(), step=epoch*num_batches + i)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_loss = np.mean(running_losses)\n",
    "    logger.add_scalar(\"loss/train\", mean_loss, step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\p.peng\\Anaconda3\\envs\\stockencoder_env\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:366: RuntimeWarning: invalid value encountered in log\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000e+10,  2.2513e-01, -1.0000e+10,  8.9167e-01,  9.5669e-01],\n",
       "        [-1.0000e+10,  2.2591e-01, -1.0000e+10,  8.9041e-01,  9.5619e-01],\n",
       "        [-1.0000e+10,  2.2721e-01, -1.0000e+10,  8.8854e-01,  9.5544e-01],\n",
       "        ...,\n",
       "        [-1.0000e+10,  2.7621e-01, -6.6862e+00,  8.8338e-01,  9.2140e-01],\n",
       "        [-1.0000e+10,  2.7616e-01, -2.5919e+00,  8.8354e-01,  9.2150e-01],\n",
       "        [-1.0000e+10,  2.7332e-01, -1.0000e+10,  8.9210e-01,  9.2715e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data[(1, dt.date(2022, 1, 1))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
